ditto {
  extensions {
    search-update-observer = org.eclipse.ditto.thingsearch.service.updater.actors.DefaultSearchUpdateObserver
    query-criteria-validator = org.eclipse.ditto.thingsearch.service.persistence.query.validation.DefaultQueryCriteriaValidator
    caching-signal-enrichment-facade-provider = org.eclipse.ditto.thingsearch.service.persistence.write.streaming.DittoCachingSignalEnrichmentFacadeProvider
    pre-enforcer-provider {
      extension-class = org.eclipse.ditto.policies.enforcement.pre.PreEnforcerProvider
      extension-config = {
        pre-enforcers = []
      }
    }
    search-update-mapper = "org.eclipse.ditto.thingsearch.service.persistence.write.streaming.DefaultSearchUpdateMapper"
  }
  mapping-strategy.implementation = "org.eclipse.ditto.thingsearch.api.ThingSearchMappingStrategies"

  persistence.operations.delay-after-persistence-actor-shutdown = 5s
  persistence.operations.delay-after-persistence-actor-shutdown = ${?DELAY_AFTER_PERSISTENCE_ACTOR_SHUTDOWN}

  mongodb {

    uri = "mongodb://user-name-1234-5678-abcdefg:password12345@first.hostname.com:10000,second.hostname.com:20000,third.hostname.com:30000,fourth.hostnamefifth.hostname.com:50000,sixth.hostname.com:60000,seventh.hostname.com:65000/database-name?replicaSet=streched-0003&maxIdleTimeMS=240000&w=majority&readPreference=primaryPreferred&ssl=true&sslInvalidHostNameAllowed=true"

    database = "searchDB"
    database = ${?MONGO_DB_DATABASE}

    pool {
      maxSize = 1000
      maxSize = ${?MONGO_DB_CONNECTION_POOL_SIZE}
      maxIdleTime = 1m
      maxIdleTime = ${?MONGO_DB_CONNECTION_POOL_IDLE_TIME}
      maxWaitTime = 30s
      maxWaitTime = ${?MONGO_DB_CONNECTION_POOL_WAIT_TIME}
      jmxListenerEnabled = false
      jmxListenerEnabled = ${?MONGO_DB_CONNECTION_POOL_JMX_LISTENER_ENABLED}
    }

    breaker {
      maxFailures = 5 # defines ater how many failures the circuit breaker should open
      maxFailures = ${?BREAKER_MAXFAILURES}
      timeout {
        call = 5s # MongoDB Timeouts causing the circuitBreaker to open - "0s" disables timeouts opening the breaker
        call = ${?BREAKER_TIMEOUT}
        reset = 10s # after this time in "Open" state, the cicuitBreaker is "Half-opened" again
        reset = ${?BREAKER_RESET}
      }
    }

    monitoring {
      commands = true
      commands = ${?MONGODB_MONITORING_COMMANDS_ENABLED}
      connection-pool = true
      commands = ${?MONGODB_MONITORING_CONNECTION_POOL_ENABLED}
    }
  }

  search {
    mongo-hints-by-namespace = ${?MONGO_HINTS_BY_NAMESPACE}

    index-initialization {
      #indices should be created within this application
      enabled = true
      enabled = ${?INDEX_INITIALIZATION_ENABLED}
    }

    updater {
      max-idle-time = 15m
      max-idle-time = ${?ACTIVITY_CHECK_INTERVAL}

      event-processing-active = true
      event-processing-active = ${?EVENT_PROCESSING_ACTIVE}

      // how often to poll shard region for state updates
      sharding-state-poll-interval = 15s
      sharding-state-poll-interval = ${?SHARDING_STATE_POLL_INTERVAL}

      background-sync {
        enabled = true
        enabled = ${?BACKGROUND_SYNC_ENABLED}

        quiet-period = 8m
        quiet-period = ${?BACKGROUND_SYNC_QUIET_PERIOD}

        idle-timeout = 5m
        idle-timeout = ${?BACKGROUND_SYNC_IDLE_TIMEOUT}

        tolerance-window = 20m
        tolerance-window = ${?BACKGROUND_SYNC_TOLERANCE_WINDOW}

        policy-ask-timeout = 10s
        policy-ask-timeout = ${?BACKGROUND_SYNC_POLICY_ASK_TIMEOUT}

        keep {
          events = 50
          events = ${?BACKGROUND_SYNC_KEEP_EVENTS}
        }

        throttle {
          throughput = 100
          throughput = ${?BACKGROUND_SYNC_THROTTLE_THROUGHPUT}

          period = 10s
          period = ${?BACKGROUND_SYCN_THROTTLE_PERIOD}
        }

        # handle failures/stalling/expired cursors
        min-backoff = 1s
        min-backoff = ${?BACKGROUND_SYNC_MIN_BACKOFF}

        max-backoff = 2m
        max-backoff = ${?BACKGROUND_SYNC_MAX_BACKOFF}

        max-restarts = 180 // give up stream resumption after about 6 hours = 180 * 120s
        max-restarts = ${?BACKGROUND_SYNC_MAX_RESTARTS}

        recovery = 5m // assume upstream healthy if no error happened for this long
        recovery = ${?BACKGROUND_SYNC_RECOCVERY}
      }

      stream {
        // arrays bigger than this are not indexed
        max-array-size = 0
        max-array-size = ${?THINGS_SEARCH_UPDATER_STREAM_MAX_ARRAY_SIZE}

        // minimum delay between event dumps
        write-interval = 1s
        write-interval = ${?THINGS_SEARCH_UPDATER_STREAM_WRITE_INTERVAL}

        // timeout for messages to Things-shard
        ask-timeout = 30s
        ask-timeout = ${?THINGS_SEARCH_UPDATER_STREAM_ASK_TIMEOUT}

        // retrieval of things and policy-enforcers
        retrieval {
          // upper bound of parallel SudoRetrieveThing commands (by extension, parallel loads of policy enforcer cache)
          parallelism = 16
          parallelism = ${?THINGS_SEARCH_UPDATER_STREAM_RETRIEVAL_PARALLELISM}

          // back-offs in case of failure
          exponential-backoff {
            min = 1s
            max = 2m
            random-factor = 2.0
          }
        }

        // writing into the persistence
        persistence {
          // how many bulk writes to request in parallel; must be a power of 2
          parallelism = 2
          parallelism = ${?THINGS_SEARCH_UPDATER_STREAM_PERSISTENCE_PARALLELISM}

          // backoffs in case of failure
          exponential-backoff {
            min = 1s
            max = 2m
            random-factor = 2.0
          }
        }

        policy-cache {
          dispatcher = "policy-enforcer-cache-dispatcher"
          retry-delay = 1s
          maximum-size = 20000
          expire-after-write = 2h
          expire-after-access = 30m
        }
        thing-cache {
          dispatcher = "thing-cache-dispatcher"
          retry-delay = 1s
          maximum-size = 20000
          expire-after-write = 2h
          expire-after-access = 30m
        }
      }
    }
  }

}

akka {
  # disable coordinated shutdown for tests
  coordinated-shutdown.terminate-actor-system = off
  coordinated-shutdown.run-by-actor-system-terminate = off

  cluster {
    sharding {
      role = "search"
    }

    roles = [
      "search",
      "blocked-namespaces-aware"
    ]
  }
}

blocked-namespaces-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 4
    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 3.0
    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 32
    parallelism-max = ${?DEFAULT_DISPATCHER_PARALLELISM_MAX}
  }
  throughput = 5
}

policy-enforcer-cache-dispatcher {
  type = Dispatcher
  executor = "thread-pool-executor"
}

thing-cache-dispatcher {
  type = Dispatcher
  executor = "thread-pool-executor"
}

search-dispatcher {
  type = PinnedDispatcher
  executor = "thread-pool-executor"
}
